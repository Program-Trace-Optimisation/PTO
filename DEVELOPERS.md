# Core concepts

To understand the code as a developer, the following concepts are essential:

* There is `base` PTO, and then there are two extensions which are crucial for good optimisation behaviour:
  * `fine_distributions`, with `repair`
  * `automatic_names`.
* The core code is organised in layers partly reflecting those extensions. TODO explain more here.
* The `run` method detailed in our README hides all of this complexity from users. There are multiple `run` methods for the multiple layers, but the user will only `from pto import run` which gives the user-facing version.
* The trace operators - initialisation, mutation, and combination operators which operate on traces (ie genotypes) and are used in PTO solvers - are implemented as compound operators, where the primitives are individual random decisions.
* Each individual random decision in a generator is made by some call to a PTO `rnd` method, which corresponds to a same-named method in the Python `random` module. `rnd.random()` gives a continuous variable with some distribution, `rnd.randrange` gives an ordinal variable, and `rnd.choice` gives a categorical variable. All other distributions can be composed out of these. For each of these, PTO models the distribution with a class which knows how to do initialisation, mutation, and combination. We call these distribution operators. In `base` PTO, initialisation is just sampling, and mutation is just re-sampling, which is a "coarse" change. Combination is just choosing the value from one or other parent. In both mutation and combination, it could happen that the offspring calls the same `rnd` method in the same trace location, but with different arguments. In that case, in `base` PTO, both mutation and combination just fall back to re-sampling, which is a "coarse" change.
* In `fine_distribution` both mutation and crossover are smarter, for continuous and ordinal variables, taking better advantage of what we know about the specific distribution to achieve a "fine" change. Also in `fine_distribution`, for continuous, ordinal, and categorical variables, smart `repair` methods try to re-use values from parents as much as possible when doing mutation and combination, even if the random call in the offspring has arguments which are not the same as the arguments in the parent.
* In PTO, traces are represented as `dict` objects. Each key represents a `rnd` call - analogous to a locus in a genotype, and each value represents the value stored there - analogous to an allele. In `base` PTO, traces are linear, that is they are organised as a sequence of random decisions, similar to PODI and Decision Chain Encoding. Therefore, the keys are just sequential integers. In PTO with `automatic_names` instead the keys are structured to represent the location of the `rnd` call in the execution trace of the generator in a structured way, that is the include the location in the generator's program flow (conditionals and loops and recursions). Thanks to the structure of program flow, we can then view the trace as a tree. TODO describe an example here.
* The default in `run()` is to use the best-behaving operators, which means using: `run(..., name_type='str', dist_type='fine')`. The defaults can be over-ridden:
  * `name_type` can be `lin` or `str`
  * `dist_type` can be `coarse` or `fine`. The latter includes switching on `repair`.
  * However, the defaults **should not** be over-ridden by users or even by researcher. A typical experiment, eg comparing `lin` versus `str` performance, is not a sensible experiment unless the researcher knows what they're doing.
* The trace operators and distribution operators described above are provided by the `Op` class. So, solvers just use an instance of `Op`, eg `offspring = self.op.mutate_ind(individual)`. To create an instance we would need to pass in the generator and fitness function.
* If we want to do experiments with PTO other than just using `run`, to make it easy to set it up correctly, we have provided the special `Solver` option `run(generator, fitness, ..., Solver='search_operators')` which doesn't do a real run, it just sets up an instance of `Op`, which can be used eg for experiments studying the behaviour of the operators in isolation.

