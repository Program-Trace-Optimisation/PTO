{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg-T43ycBgrR",
        "outputId": "bbe06a08-fb43-447d-b3b4-b6612f5c5d21"
      },
      "outputs": [],
      "source": [
        "pip install git+https://github.com/Program-Trace-Optimisation/PTO.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OneMax in PTO\n",
        "\n",
        "This is a minimal example. We import `run` and `rnd`, and our `generator` is written to make random decisions using `rnd`. Our objective is just `sum`. The `max` function tells PTO that we are maximising, ie larger values of the objective are better. The `run` function is then the single-function API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DEbQ7X4zFfvf"
      },
      "outputs": [],
      "source": [
        "from pto import run, rnd\n",
        "def generator(): return [rnd.choice([0, 1]) for i in range(10)]\n",
        "(pheno, geno), fx = run(generator, sum, better=max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3-t2NIyFuTw",
        "outputId": "ff533f54-fdb3-4f70-b7e0-26ea92ae534e"
      },
      "outputs": [],
      "source": [
        "print(f'Genotype {geno}')\n",
        "print(f'Solution {pheno}')\n",
        "print(f'Fitness {fx}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sphere in PTO\n",
        "\n",
        "Another basic example, this time minimising the sum of squares. Here, the `generator` has an argument `N` giving the problem size. We can pass such an argument to `run` using `gen_args`. This example also demonstrates we can add a `callback` in `run`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pto import run, rnd\n",
        "N = 10\n",
        "def generator(N): # standard uniform initialisation \n",
        "    return [rnd.uniform(-1, 1) for i in range(N)]\n",
        "def fitness(vector): return sum([x**2 for x in vector])   \n",
        "\n",
        "(pheno, geno), fx = run(generator, fitness, \n",
        "                        gen_args=(N,), \n",
        "                        callback=lambda x: print(f\"Hello from Solver callback! {x}\"),\n",
        "                        better=min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Genotype {geno}')\n",
        "print(f'Solution {pheno}')\n",
        "print(f'Fitness {fx}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Symbolic Regression in PTO\n",
        "\n",
        "This example shows how to pass arguments also to the objective function.\n",
        "\n",
        "Symbolic regression is an interesting problem for PTO, because the promise of PTO is that it automatically implicitly defines operators suitable for the problem, given the `generator`. And indeed, the implicit operators here will resemble known mutation and homologous tree crossover operators - see our papers for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pto import run, rnd\n",
        "import random # for generating problem data\n",
        "\n",
        "    \n",
        "#################\n",
        "# INSTANCE DATA #\n",
        "#################\n",
        "         \n",
        "n_vars = 3 # problem size (number of input variables)\n",
        "        \n",
        "func_set = [('and', 2), ('or', 2), ('not', 1)] # functions set\n",
        "term_set = ['x1', 'x2', 'x3'] # terminals set\n",
        "        \n",
        "target = lambda x1, x2, x3: x1 or x2 or not x3 # target function\n",
        "    \n",
        "# create training set\n",
        "n = 10 # training set size\n",
        "X_train = [[random.choice([0, 1]) for _ in range(3)] for _ in range(n)] # training inputs\n",
        "y_train = [target(*xi) for xi in X_train] # training outputs\n",
        "\n",
        "better = min\n",
        "        \n",
        "\n",
        "######################\n",
        "# SOLUTION GENERATOR #\n",
        "######################\n",
        "\n",
        "# generate random expression\n",
        "def generator(func_set, term_set): \n",
        "\n",
        "    def rnd_expr(): # Growth Initialisation\n",
        "        if rnd.random() < len(term_set)/(len(term_set)+len(func_set)):\n",
        "            expr = rnd.choice(term_set)\n",
        "        else:\n",
        "            func, arity = rnd.choice(func_set)\n",
        "            if arity == 1:\n",
        "                expr = '(%s %s)' % (func, rnd_expr())\n",
        "            else: # arity = 2\n",
        "                expr = '(%s %s %s)' % (rnd_expr(), func, rnd_expr())\n",
        "        return expr\n",
        "        \n",
        "    return rnd_expr()\n",
        "\n",
        "\n",
        "####################\n",
        "# FITNESS FUNCTION #\n",
        "####################\n",
        "\n",
        "# fitness\n",
        "def fitness(expr, X, y):\n",
        "    \n",
        "    # string to function\n",
        "    f = eval(\"lambda x1, x2, x3 : \" + expr)\n",
        "    \n",
        "    # predictions on traning set\n",
        "    yhat = [f(*xi) for xi in X] \n",
        "    \n",
        "    # error on traing set\n",
        "    err = sum(abs(yhati - yi) for (yhati, yi) in zip(yhat, y))\n",
        "    \n",
        "    return err\n",
        "\n",
        "\n",
        "\n",
        "(pheno, geno), fx = run(generator, fitness, \n",
        "                        gen_args=(func_set, term_set), \n",
        "                        fit_args=(X_train, y_train), better=better)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Genotype {geno}')\n",
        "print(f'Solution {pheno}')\n",
        "print(f'Fitness {fx}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
